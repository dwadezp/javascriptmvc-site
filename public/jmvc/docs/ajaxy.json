C({"name": "ajaxy", "type": "page", "comment": "<p>This tutorial walks you through building a simple widget\nthat listens for changes in the browser location hash\nand updates the content of the page.  It demonstrates how to make\na site Google crawlable and searchable.</p>\n\n<h2>The App</h2>\n\n<p>We'll make a mini app that updates the contents of page with an\nAjax request when a user clicks on a navigation link. Then, we'll make this searchable\nwith the <code>ajaxy/scripts/crawl.js</code> script.</p>\n\n<div class='demo_wrapper' data-demo-src='tutorials/ajaxy/ajaxy.html'></div>\n\n<p>The crawl script generates html pages that Google can use as a representation\nof the content of an Ajax application.  Read Google's documentation on its\n[http://code.google.com/web/ajaxcrawling/docs/getting-started.html Ajax crawling API]\n before continuing this tutorial.</p>\n\n<h2>Setup</h2>\n\n<p>[installing Download and install] the latest version of JavaScriptMVC.</p>\n\n<p>After installing JavaScriptMVC, open a command line to \nthe [steal.static.root steal.root] folder (where you unzipped \nJavaScriptMVC).  </p>\n\n<p>We'll use the application generator to generate an application\nskeleton folder.  Run:</p>\n\n<pre><code>js jquery/generate/app ajaxy\n</code></pre>\n\n<h2>The Code</h2>\n\n<p>In the generated ajaxy folder, you'll find <code>ajaxy.html</code>\nand <code>ajaxy.js</code>.  We'll add a content area\nand few links to \n<code>ajaxy.html</code>.  When we click on  links,\nwe'll make <code>ajaxy.js</code> load content into\nthe content area.</p>\n\n<p>Change <code>ajaxy.html</code> so it looks like:</p>\n\n<pre><code class='xml'>&lt;!DOCTYPE HTML>\n&lt;html lang=\"en\">\n    &lt;head>\n        &lt;title>Ajaxy&lt;/title>\n        &lt;meta name=\"fragment\" content=\"!\">\n    &lt;/head>\n    &lt;body>\n        &lt;a href='#!videos'>Videos&lt;/a>\n        &lt;a href='#!articles'>Articles&lt;/a>\n        &lt;a href='#!images'>Images&lt;/a>\n        &lt;div id='content'>&lt;/div>\n        &lt;script type='text/javascript' \n            src='../steal/steal.js?ajaxy,development'>     \n        &lt;/script>\n    &lt;/body>\n&lt;/html></code></pre>\n\n<p>Notice that the page includes a <code>&lt;meta name=\"fragment\" content=\"!\"&gt;</code>\ntag.  This tells to Google to process <code>ajaxy.html</code> as having Ajax content.</p>\n\n<p>Next, add some content to show when these links are clicked.  Put the following content\nin each file:</p>\n\n<p><strong>ajaxy/fixtures/articles.html</strong></p>\n\n<pre><code class='xml'>&lt;h1>Articles&lt;/h1>\n&lt;p>Some articles.&lt;/p></code></pre>\n\n<p><strong>ajaxy/fixtures/images.html</strong></p>\n\n<pre><code class='xml'>&lt;h1>Images&lt;/h1>\n&lt;p>Some images.&lt;/p></code></pre>\n\n<p><strong>ajaxy/fixtures/videos.html</strong></p>\n\n<pre><code class='xml'>&lt;h1>Videos&lt;/h1>\n&lt;p>Some videos.&lt;/p></code></pre>\n\n<p>Finally, change <code>ajaxy.js</code> to look like:</p>\n\n<pre><code>$.Controller('Ajaxy',{\n    init : function(){\n        this.updateContent()\n    },\n    \"{window} hashchange\" : function(){\n        this.updateContent();\n    },\n    updateContent : function(){\n        var hash = window.location.hash.substr(2),\n            url = \"fixtures/\"+(hash || \"videos\")+\".html\";\n\n        // postpone reading the html \n        steal.html.wait();\n\n        $.get(url, {}, this.callback('replaceContent'),\"text\" )\n    },\n    replaceContent : function(html){\n        this.element.html(html);\n\n        // indicate the html is ready to be crawled\n        steal.html.ready();\n    }\n})\n\n$('#content').ajaxy()\n</code></pre>\n\n<p>When a hashchange (<code>\"{window} hashchange\"</code>) event occurs, Ajaxy\nuses the <code>window.location.hash</code> value to make a \nrequest (<code>$.get</code>)\nfor content in the<code>fixtures</code> folder.  </p>\n\n<p>When the content is retrieved, it replaces the element's \nhtml (<code>this.element.html(...)</code>).</p>\n\n<p>Ajaxy also calls <code>updateContent</code> to load content when\nthe page loads initially. </p>\n\n<h2>Crawling and scraping</h2>\n\n<p>To crawl your site and generate google-searchable html, run:</p>\n\n<pre><code class='none'>js ajaxify/scripts/crawl.js</code></pre>\n\n<p>This script peforms the following actions:</p>\n\n<ol>\n<li>Opens a page in a headless browser.</li>\n<li>Waits until its content is ready.</li>\n<li>Scrapes its contents.</li>\n<li>Writes the contents to a file.</li>\n<li>Adds any links in the page that start with #! to be indexed</li>\n<li>Changes <code>window.location.hash</code> to the next index-able page</li>\n<li>Goto #2 and repeats until all pages have been loaded</li>\n</ol>\n\n<h2>Pausing the html scraping.</h2>\n\n<p>By default, the contents are scraped immediately after the page's scripts have loaded or\nthe window.location.hash has changed.  The Ajax request for content\nhappens asynchronously so we have to tell [steal.html] to wait to scrape the content.</p>\n\n<p>To do this, Ajaxy calls:</p>\n\n<pre><code>steal.html.wait();\n</code></pre>\n\n<p>before the Ajax request.  And when the page is ready, Ajaxy calls:</p>\n\n<pre><code>steal.html.ready();\n</code></pre>\n\n<h2>Getting Google To Crawl Your Site</h2>\n\n<p>If you haven't already, read up on \nGoogle's [http://code.google.com/web/ajaxcrawling/docs/getting-started.html Ajax crawling API].</p>\n\n<p>When google wants to crawl your site, it will send a \nrequest to your page with <code><em>escaped</em>fragment_=<code>.  When this happens, redirect\ngoogle to the generated html page.  Yes, it's that easy!</p>", "title": "Searchable Ajax Apps", "parents": ["tutorials"], "order": 6, "src": "tutorials/ajaxy/ajaxy.md", "children": []})