C({"name": "steal.html.crawl", "params": {"url": {"description": "<p>the starting page to crawl</p>", "type": "Object", "optional": false, "order": 0, "name": "url"}, "opts": {"description": "<p>the location to put the crawled content.</p>", "type": "String|Object", "optional": false, "order": 1, "name": "opts"}}, "ret": {"type": "undefined", "description": ""}, "type": "function", "comment": "<p>Loads an ajax driven page and generates the html for google to crawl.</p>\n\n<p>This crawler indexes an entire Ajax site.  It</p>\n\n<ol>\n<li>Opens a page in a headless browser.</li>\n<li>Waits until its content is ready.</li>\n<li>Scrapes its contents.</li>\n<li>Writes the contents to a file.</li>\n<li>Adds any links in the page that start with #! to be indexed</li>\n<li>Changes <code>window.location.hash</code> to the next index-able page</li>\n<li>Goto #2 and repeats until all pages have been loaded</li>\n</ol>\n\n<h2>2. Wait until content is ready.</h2>\n\n<p>By default, [steal.html] will just wait until all scripts have finished loading\nbefore scraping the page's contents.  To delay this, use\n[steal.html.delay] and [steal.html.ready].</p>\n\n<h2>3. Write the contents to a file.</h2>\n\n<p>You can change where the contents of the file are writen to by changing\nthe second parameter passed to <code>crawl</code>.</p>", "parents": ["steal.html"], "src": "../steal/html/crawl/crawl.js", "children": []})